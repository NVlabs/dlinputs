{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (shardwriter.py, line 137)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"dlinputs/shardwriter.py\"\u001b[0;36m, line \u001b[0;32m137\u001b[0m\n\u001b[0;31m    assert isinstance(v, (str, buffer)), (k, type(v),), \"converter didn't yield a string\"\u001b[0m\n\u001b[0m                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import scipy.ndimage as ndi\n",
    "import pylab as pl\n",
    "import matplotlib as mpl\n",
    "from IPython import display\n",
    "from itertools import islice\n",
    "rc(\"image\", cmap=\"gray\")\n",
    "import dlinputs; reload(dlinputs); dli = dlinputs\n",
    "#from dlinputs import inputs as dli; reload(dli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data is often stored in the file system. The `dlinputs` library provides a number of convenient iterators over such data:\n",
    "\n",
    "- `itdirtree` - iterates over samples stored in a directory tree\n",
    "- `itbasenames` - the dataset is a file containing basenames, plus a list of extensions\n",
    "- `ittabular` - the dataset is a file containing rows with filenames / data\n",
    "\n",
    "In addition, `find_file` and `find_directory` can be used to write input pipelines that work in many different environments and search for datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import dlinputs; reload(dlinputs); dli = dlinputs\n",
    "data = dli.itdirtree(\"testdata/dirdata\", \"png,cls\", size=6) | \\\n",
    "       dli.itmap(png=dli.pilreads, cls=int)\n",
    "sample = data.next()\n",
    "imshow(sample[\"png\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basename Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed 5q testdata/dirdata.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dli.itbasenames(\"testdata/dirdata.list\", \"png,cls\", size=6) | \\\n",
    "       dli.itmap(png=dli.pilreads, cls=int)\n",
    "sample = data.next()\n",
    "print sample.keys()\n",
    "print sample[\"__path__\"]\n",
    "imshow(sample[\"png\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Basename Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find testdata/dirdata -name '*.png' > basenames\n",
    "!sed 3q basenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dli.itbasenames(\"basenames\", \"png,cls\", size=6) | \\\n",
    "       dli.itmap(png=dli.pilreads, cls=int)\n",
    "sample = data.next()\n",
    "print sample.keys()\n",
    "print sample[\"__path__\"]\n",
    "imshow(sample[\"png\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular Dataset Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed 5q testdata/dirdata.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dli.ittabular(\"testdata/dirdata.tsv\", \"png,cls\", size=6) | \\\n",
    "       dli.itmap(png=dli.pilreads, cls=int)\n",
    "sample = data.next()\n",
    "print sample.keys()\n",
    "print sample[\"__path__png\"]\n",
    "imshow(sample[\"png\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Data in Tabular Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed 5q testdata/dirdata.tsv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dli.ittabular(\"testdata/dirdata.tsv2\", \"png,_cls\", size=6) | \\\n",
    "       dli.itmap(png=dli.pilreads, _cls=int)\n",
    "sample = data.next()\n",
    "print sample.keys()\n",
    "print sample[\"__path__png\"]\n",
    "imshow(sample[\"png\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/work/DATABASES:./testdata\"\n",
    "dli.find_file(path, \"sample.db\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/work:./testdata\"\n",
    "dli.find_directory(path, \"dirdata\", \"10.png\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Reader\n",
    "\n",
    "Sqlite databases are convenient for local datasets. They can be up to several terabytes large. `itsqlite` returns dictionaries containing\n",
    "each column as a field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sqlite3 testdata/sample.db .schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (dli.itsqlite(\"testdata/sample.db\") |\n",
    "        dli.itmap(image=dli.pilgray, cls=int))\n",
    "for sample in data:\n",
    "    imshow(sample[\"image\"])\n",
    "    print sample[\"cls\"]\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tar Record Files\n",
    "\n",
    "Tar record files are regular tar files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -ztvf testdata/sample.tgz | sed 5q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consecutive files with the same\n",
    "basename are returned as items in a dictionary; the extension is used\n",
    "as the key to each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dli.ittarreader(\"testdata/sample.tgz\")\n",
    "for sample in data:\n",
    "    print sample.keys()\n",
    "    print sample[\"__key__\"]\n",
    "    print repr(sample[\"cls\"])\n",
    "    print repr(sample[\"png\"])[:30]\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, the output from an `ittarreader` is piped through something that decodes the string/buffer fields (`itmap`) and renames fields (`itren`). Decoders in `itmap` are just functions that map the contents of a field to new contents. The `dli.pilgray` function decodes a PNG-compressed image into a grayscale image represented as a numpy rank 2 array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (dli.ittarreader(\"testdata/sample.tgz\") |\n",
    "        dli.itmap(png=dli.pilgray, cls=int) |\n",
    "        dli.itren(image=\"png\", cls=\"cls\"))\n",
    "for sample in data:\n",
    "    imshow(sample[\"image\"])\n",
    "    print sample[\"cls\"]\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ittarreader` can also read from URLs. This can be any web server, although often it is an S3-compatible storage server like Minio, Minio XL, Ceph, or Swift.\n",
    "\n",
    "For desktop installations, the local Minio server is convenient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/bin/bash -c 'cd testdata && nohup python -m SimpleHTTPServer 9000 &'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = (dli.ittarreader(\"http://localhost:9000/sample.tgz\") |\n",
    "        dli.itmap(png=dli.pilgray, cls=int))\n",
    "for sample in data:\n",
    "    imshow(sample[\"png\"])\n",
    "    print sample[\"cls\"]\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharded Files\n",
    "\n",
    "For larger datasets, sharding is a good idea. Shards are stored in JSON-formatted URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O - http://localhost:9000/imagenet.shards | sed 10q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding is otherwise just like regular `ittarfile`. Note that the shard reader randomizes shard order by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (dli.ittarshards(\"http://localhost:9000/imagenet.shards\") |\n",
    "        # dli.itinfo() |\n",
    "        dli.itmap(png=dli.pilrgb, cls=int))\n",
    "for sample in data:\n",
    "    imshow(sample[\"png\"])\n",
    "    print sample[\"cls\"]\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make input pipelines movable between different environments, you can also specify an `urlpath`, a list of URL roots to search (you can also supply these as a whitespace separated string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlpath = \"\"\"\n",
    "http://mars:9000/\n",
    "http://jupiter:9000/\n",
    "http://localhost:9000/\n",
    "\"\"\".strip().split()\n",
    "\n",
    "data = (dli.ittarshards(\"imagenet.shards\", urlpath=urlpath) | \\\n",
    "        dli.itmap(png=dli.pilrgb, cls=int))\n",
    "for sample in data:\n",
    "    imshow(sample[\"png\"])\n",
    "    print sample[\"cls\"]\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Input Filters\n",
    "\n",
    "There are more pipeline components:\n",
    "\n",
    "- `itshuffle` shuffles samples inline\n",
    "- `itstandardize` performs image size standardization\n",
    "- `itbatch` performs batching of inputs\n",
    "\n",
    "More are being added to `dlpipes`, including in-memory and on-disk caching, more data augmentation, and distributed and parallel pipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (dli.ittarshards(\"http://localhost:9000/imagenet.shards\") |\n",
    "        dli.itshuffle(1000) |\n",
    "        dli.itmap(png=dli.pilrgb, cls=int) |\n",
    "        dli.itren(image=\"png\", cls=\"cls\") |\n",
    "        dli.itstandardize((256,256)) |\n",
    "        dli.itbatch(5))\n",
    "for sample in data:\n",
    "    print sample[\"image\"].shape\n",
    "    imshow(sample[\"image\"][0])\n",
    "    print sample[\"cls\"]\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Loadable Inputs and Models\n",
    "\n",
    "In many applications, it's useful to separate the input pipelines and model definitions from the source code of the application. The `dlpipes.loadable` module addresses this problem. It allows input pipelines and models to be defined with arbitrary Python code, but to be imported by file name rather than using the `import` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat input-sample.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that loadable input pipelines can be written using arbitrary Python code; they simply need to return Python iterators.\n",
    "\n",
    "Different partitions of the dataset may get different `*_data` methods. You generally should have at least `training_data` and `test_data`. All and only datasets should have methods ending in `_data`.\n",
    "\n",
    "Loadable input pipelines and models written in Python must end in `.py`; that's because the loader will eventually also load JSON and YAML definitions of pipelines and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = dli.loadable.load_input(\"input-sample.py\")\n",
    "training_data = factory.training_data()\n",
    "training_data.next().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining dataset iterators in this way allows us to create useful tools that operate over datasets. For example, `show-input` provides information about a dataset iterators; optionally, it can also benchmark. There are other tools for broadcasting datasets over the network, dumping them into sharded files, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!./show-input input-sample.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client Server Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often useful to run some preprocessing code distributed on multiple CPU-only servers, then send the data on to the deep learning model on a GPU machine. The `zmqserver` and `itzmq` functions make this easy. These functions use a simple and time-efficient encoding of tensors in multipart ZMQ messages. With `itzmq`, it is also easily possible to connect to ZMQ-based servers written in other languages, to build efficient PUB/SUB training pipelines for training many models simultaneously, to build efficient wide area distribution trees for training data across data centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile server.py\n",
    "import dlinputs as dli\n",
    "data = dli.ittarreader(\"testdata/sample.tgz\") | \\\n",
    "       dli.itmap(png=dli.pilrgb, cls=int)\n",
    "dli.zmqserver(data, bind=\"tcp://*:17006\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!/bin/bash -c 'python ./server.py &'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dli.itzmq(connect=\"tcp://localhost:17006\")\n",
    "imshow(data.next()[\"png\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelizing Input Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factory():\n",
    "    return dli.itsqlite(\"testdata/sample.db\") | \\\n",
    "           dli.itmap(image=dli.pilreads, cls=int)\n",
    "data = factory()\n",
    "imshow(data.next()[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dli.parallel.parallelize_input(factory, 4)\n",
    "imshow(data.next()[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
