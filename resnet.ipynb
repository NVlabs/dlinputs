{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable Params: 15947114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsonti/.anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:114: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import pdb\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "\treturn nn.Conv2d(in_planes, out_planes, kernel_size=(1,1), \n",
    "\t\tstride=stride, padding=0, bias=False);\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "\treturn nn.Conv2d(in_planes, out_planes, kernel_size=(3,3), \n",
    "\t\tstride=stride, padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "\tdef __init__(self, in_planes, out_planes, downsample=False):\n",
    "\t\tsuper(BasicBlock, self).__init__()\n",
    "\n",
    "\t\tself.in_planes = in_planes\n",
    "\t\tself.out_planes = out_planes\n",
    "\n",
    "\t\tself.conv1 = conv3x3(in_planes, out_planes)\n",
    "\t\tself.bn1 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "\t\tself.conv2 = conv3x3(out_planes, out_planes)\n",
    "\t\tself.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "\t\tself.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "\t\tself.conv_skip = conv1x1(in_planes, out_planes)\n",
    "\t\tself.bn_skip = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tresidual = x.clone()\n",
    "\n",
    "\t\tx = self.conv1(x)\n",
    "\t\tx = self.bn1(x)\n",
    "\t\tx = self.relu(x)\n",
    "\n",
    "\t\tx = self.conv2(x)\n",
    "\t\tx = self.bn2(x)\n",
    "\n",
    "\t\t# Include skip connection\n",
    "\t\tif self.in_planes==self.out_planes:\n",
    "\t\t\tx = x + residual\n",
    "\t\telse:\n",
    "\t\t\tresidual = self.conv_skip(residual)\n",
    "\t\t\tresidual = self.bn_skip(residual)\n",
    "\t\t\tx = x + residual\n",
    "\n",
    "\t\tx = self.relu(x)\n",
    "\n",
    "\t\treturn x\n",
    "\n",
    "class LayerBlock(nn.Module):\n",
    "\tdef __init__(self, in_planes, out_planes, num_basic_blocks):\n",
    "\t\tsuper(LayerBlock, self).__init__()\n",
    "\n",
    "\t\ttemp = []\n",
    "\t\tfor i in range(num_basic_blocks):\n",
    "\t\t\tif i==0:\n",
    "\t\t\t\ttemp.append(BasicBlock(in_planes, out_planes))\n",
    "\t\t\telse:\n",
    "\t\t\t\ttemp.append(BasicBlock(out_planes, out_planes))\n",
    "\n",
    "\t\tself.blocks = nn.ModuleList(temp)\n",
    "\n",
    "\t\tself.maxpool = nn.MaxPool2d((2,2), stride=2)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tfor block in self.blocks:\n",
    "\t\t\tx = block(x)\n",
    "\n",
    "\t\tx = self.maxpool(x)\n",
    "\n",
    "\t\treturn x\n",
    "\n",
    "class Model(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Model, self).__init__()\n",
    "\n",
    "\t\t# img size 32x32\n",
    "\n",
    "\t\tself.conv = nn.Conv2d(3, 32, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\t\t# img size = (38-7)/2+1 = 31/2+1 = 16x16\n",
    "\n",
    "\t\tself.layer_blocks = nn.ModuleList([\n",
    "\t\t\t\tLayerBlock(32, 64, 10),\n",
    "\t\t\t\t# img size 8x8\n",
    "\n",
    "\t\t\t\tLayerBlock(64, 128, 10),\n",
    "\t\t\t\t# img size 4x4\n",
    "\t\t\t\n",
    "\t\t\t\tLayerBlock(128, 256, 10),\n",
    "\t\t\t\t# img size 2x2\n",
    "\t\t\t\n",
    "\t\t\t\t# self.layer_block4 = LayerBlock(128, 256, 7),\n",
    "\t\t\t\t# img size 1x1\n",
    "\t\t])\n",
    "\n",
    "\t\tself.avgpool = nn.AvgPool2d((2,2), stride=1)\n",
    "\t\t# img size = (2-2)/1 + 1 = 1x1\n",
    "\n",
    "\t\tfc_in_size = 256 * 1 * 1\n",
    "\n",
    "\t\tself.fc = nn.Linear(fc_in_size, 10)\n",
    "\n",
    "\t\tfor m in self.modules():\n",
    "\t\t\tif isinstance(m, nn.Conv2d):\n",
    "\t\t\t\tnn.init.kaiming_normal(m.weight.data)\n",
    "\t\t\telif isinstance(m, nn.BatchNorm2d):\n",
    "\t\t\t\tm.weight.data.fill_(1)\n",
    "\t\t\t\tm.bias.data.zero_()\n",
    "\t\t\telif isinstance(m, nn.Linear):\n",
    "\t\t\t\tm.weight.data.normal_(0, 0.01)\n",
    "\t\t\t\tm.bias.data.zero_()\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.conv(x)\n",
    "\n",
    "\t\tfor layer_block in self.layer_blocks:\n",
    "\t\t\tx = layer_block(x)\n",
    "\n",
    "\t\tx = self.avgpool(x)\n",
    "\n",
    "\t\tx = x.view(x.size(0), -1)\n",
    "\n",
    "\t\tx = self.fc(x)\n",
    "\n",
    "\t\treturn x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = MemNet()\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"Number of trainable Params: \" + str(params))\n",
    "    # print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
